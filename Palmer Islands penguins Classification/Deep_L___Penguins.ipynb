{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DEEP LEARNING WITH PYTORCH AND TENSORFLOW"
      ],
      "metadata": {
        "id": "cW9Fp5anslW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3orMXTPAqt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "3302bdec-a5fe-4487-9498-f6d0982237ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 05:57:17--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/penguins.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7086 (6.9K) [text/plain]\n",
            "Saving to: ‘penguins.csv.1’\n",
            "\n",
            "\rpenguins.csv.1        0%[                    ]       0  --.-KB/s               \rpenguins.csv.1      100%[===================>]   6.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-29 05:57:17 (66.2 MB/s) - ‘penguins.csv.1’ saved [7086/7086]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
              "100          35.0         17.9           19.2     37.25        0\n",
              "142          32.1         15.5           18.8     30.50        0\n",
              "43           44.1         19.7           19.6     44.00        0\n",
              "191          48.7         15.7           20.8     53.50        1\n",
              "27           40.5         17.9           18.7     32.00        0\n",
              "159          46.7         15.3           21.9     52.00        1\n",
              "71           39.7         18.4           19.0     39.00        0\n",
              "296          42.4         17.3           18.1     36.00        2\n",
              "283          51.3         18.2           19.7     37.50        2\n",
              "188          42.6         13.7           21.3     49.50        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e985c12d-aea3-4d3b-8243-dddffbf17c7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CulmenLength</th>\n",
              "      <th>CulmenDepth</th>\n",
              "      <th>FlipperLength</th>\n",
              "      <th>BodyMass</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>35.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>19.2</td>\n",
              "      <td>37.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>32.1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>18.8</td>\n",
              "      <td>30.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44.1</td>\n",
              "      <td>19.7</td>\n",
              "      <td>19.6</td>\n",
              "      <td>44.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>48.7</td>\n",
              "      <td>15.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>53.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>40.5</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.7</td>\n",
              "      <td>32.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>46.7</td>\n",
              "      <td>15.3</td>\n",
              "      <td>21.9</td>\n",
              "      <td>52.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>39.7</td>\n",
              "      <td>18.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>42.4</td>\n",
              "      <td>17.3</td>\n",
              "      <td>18.1</td>\n",
              "      <td>36.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>51.3</td>\n",
              "      <td>18.2</td>\n",
              "      <td>19.7</td>\n",
              "      <td>37.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>42.6</td>\n",
              "      <td>13.7</td>\n",
              "      <td>21.3</td>\n",
              "      <td>49.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e985c12d-aea3-4d3b-8243-dddffbf17c7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e985c12d-aea3-4d3b-8243-dddffbf17c7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e985c12d-aea3-4d3b-8243-dddffbf17c7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/penguins.csv\n",
        "# load the training dataset (excluding rows with null values)\n",
        "penguins = pd.read_csv('penguins.csv').dropna()\n",
        "\n",
        "# Deep Learning models work best when features are on similar scales\n",
        "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\n",
        "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
        "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
        "penguins['BodyMass'] = penguins['BodyMass']/100\n",
        "\n",
        "# The dataset is too small to be useful for deep learning\n",
        "# So we'll oversample it to increase its size\n",
        "for i in range(1,3):\n",
        "    penguins = penguins.append(penguins)\n",
        "\n",
        "# Display a random sample of 10 observations\n",
        "sample = penguins.sample(10)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Species column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2"
      ],
      "metadata": {
        "id": "CWYLr0QGGsk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
        "print(sample.columns[0:5].values, 'SpeciesName')\n",
        "for index, row in penguins.sample(10).iterrows():\n",
        "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtrZ9uo-GrdK",
        "outputId": "288e78d8-0a5b-4027-d910-e04e16070495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
            "[ 47.5 14.0 21.2 48.75 1 ] Gentoo\n",
            "[ 43.2 19.0 19.7 47.75 0 ] Adelie\n",
            "[ 36.2 17.3 18.7 33.0 0 ] Adelie\n",
            "[ 38.6 17.0 18.8 29.0 0 ] Adelie\n",
            "[ 48.5 17.5 19.1 34.0 2 ] Chinstrap\n",
            "[ 49.5 19.0 20.0 38.0 2 ] Chinstrap\n",
            "[ 46.8 14.3 21.5 48.5 1 ] Gentoo\n",
            "[ 35.3 18.9 18.7 38.0 0 ] Adelie\n",
            "[ 50.0 15.2 21.8 57.0 1 ] Gentoo\n",
            "[ 42.6 13.7 21.3 49.5 1 ] Gentoo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
        "label = 'Species'\n",
        "   \n",
        "# Split data 70%-30% into training set and test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
        "                                                    penguins[label].values,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=0)\n",
        "\n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
        "print(\"Sample of features and labels:\")\n",
        "\n",
        "# Take a look at the first 25 training features and corresponding labels\n",
        "for n in range(0,24):\n",
        "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDmxcbcaHYZ8",
        "outputId": "62794139-7169-4ce9-b1ae-3e2134fa1514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 957, Test Set: 411 \n",
            "\n",
            "Sample of features and labels:\n",
            "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
            "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
            "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
            "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
            "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
            "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
            "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
            "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
            "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
            "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
            "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
            "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
            "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
            "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
            "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
            "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
            "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
            "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
            "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
            "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
            "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
            "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
            "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
            "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and import the PyTorch libraries\n"
      ],
      "metadata": {
        "id": "x_xH3v5IHmJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhbhjjj0Hngl",
        "outputId": "c5473cdd-0fc4-4355-a5b2-dfe3d638da19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.9.0%2Bcpu-cp38-cp38-linux_x86_64.whl (175.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.10.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.10.0%2Bcpu-cp38-cp38-linux_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cpu) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cpu) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cpu) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0+cpu torchaudio-0.9.0 torchvision-0.10.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "\n",
        "# Set random seed for reproducability\n",
        "torch.manual_seed(0)\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLxxlwCDIDNJ",
        "outputId": "c9665e00-1977-4379-86d8-99e2c62fad38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported - ready to use PyTorch 1.9.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the data for PyTorch\n",
        "PyTorch makes use of data loaders to load training and validation data in batches. We've already loaded the data into numpy arrays, but we need to wrap those in PyTorch datasets (in which the data is converted to PyTorch tensor objects) and create loaders to read batches from those datasets."
      ],
      "metadata": {
        "id": "_n-lsPtEJq1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BHKajZKJN_m",
        "outputId": "548c00cb-5a98-45de-cb3c-b68120a61348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a neural network\n",
        "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
        "\n",
        "-An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a ReLU activation function.\n",
        "\n",
        "-A hidden layer that receives ten inputs and applies a ReLU activation function\n",
        "\n",
        "-An output layer that generates a non-negative numeric output for each penguin species (which a loss function will translate into classification probabilities for each of the three possible penguin species).\n"
      ],
      "metadata": {
        "id": "QPSGmkAOJ2iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of hidden layer nodes\n",
        "hl = 10\n",
        "\n",
        "# Define the neural network\n",
        "class PenguinNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PenguinNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(features), hl)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        self.fc3 = nn.Linear(hl, len(penguin_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Create a model instance from the network\n",
        "model = PenguinNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTG0SofAJ9lT",
        "outputId": "c01493ff-e9df-4287-cc7e-2fa4fcb3338f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PenguinNet(\n",
            "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
        "\n",
        "To do this, we'll create a function to train and optimize the model, and function to test the model. Then we'll call these functions iteratively over 50 epochs, logging the loss and accuracy statistics for each epoch."
      ],
      "metadata": {
        "id": "M_Kp_4liNqX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "           \n",
        "            \n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "            \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D2B2MkfNtLb",
        "outputId": "8ba3bc69-ef9d-4f67-f8bf-f8fbca8da1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 1.102661\n",
            "Validation set: Average loss: 0.933957, Accuracy: 189/411 (46%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.905142\n",
            "Validation set: Average loss: 0.870184, Accuracy: 227/411 (55%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.863389\n",
            "Validation set: Average loss: 0.830578, Accuracy: 229/411 (56%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.829038\n",
            "Validation set: Average loss: 0.797620, Accuracy: 231/411 (56%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.800002\n",
            "Validation set: Average loss: 0.769257, Accuracy: 242/411 (59%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.774563\n",
            "Validation set: Average loss: 0.744467, Accuracy: 252/411 (61%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.752545\n",
            "Validation set: Average loss: 0.722871, Accuracy: 258/411 (63%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.733695\n",
            "Validation set: Average loss: 0.704833, Accuracy: 274/411 (67%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.716937\n",
            "Validation set: Average loss: 0.689475, Accuracy: 285/411 (69%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.701415\n",
            "Validation set: Average loss: 0.675943, Accuracy: 297/411 (72%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.687584\n",
            "Validation set: Average loss: 0.662878, Accuracy: 310/411 (75%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.674797\n",
            "Validation set: Average loss: 0.650033, Accuracy: 313/411 (76%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.662381\n",
            "Validation set: Average loss: 0.636594, Accuracy: 309/411 (75%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.650715\n",
            "Validation set: Average loss: 0.624652, Accuracy: 318/411 (77%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.639461\n",
            "Validation set: Average loss: 0.614669, Accuracy: 339/411 (82%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.628928\n",
            "Validation set: Average loss: 0.604216, Accuracy: 341/411 (83%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.618988\n",
            "Validation set: Average loss: 0.594338, Accuracy: 347/411 (84%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.609849\n",
            "Validation set: Average loss: 0.584512, Accuracy: 352/411 (86%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.601573\n",
            "Validation set: Average loss: 0.576730, Accuracy: 363/411 (88%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.594156\n",
            "Validation set: Average loss: 0.568305, Accuracy: 364/411 (89%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.587452\n",
            "Validation set: Average loss: 0.560972, Accuracy: 364/411 (89%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.581301\n",
            "Validation set: Average loss: 0.556154, Accuracy: 377/411 (92%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.575911\n",
            "Validation set: Average loss: 0.549683, Accuracy: 376/411 (91%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.571007\n",
            "Validation set: Average loss: 0.546699, Accuracy: 381/411 (93%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.566462\n",
            "Validation set: Average loss: 0.544358, Accuracy: 387/411 (94%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.562462\n",
            "Validation set: Average loss: 0.541302, Accuracy: 389/411 (95%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.558887\n",
            "Validation set: Average loss: 0.539260, Accuracy: 396/411 (96%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.555284\n",
            "Validation set: Average loss: 0.535518, Accuracy: 399/411 (97%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.552216\n",
            "Validation set: Average loss: 0.532615, Accuracy: 399/411 (97%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.549529\n",
            "Validation set: Average loss: 0.529061, Accuracy: 399/411 (97%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.547023\n",
            "Validation set: Average loss: 0.526766, Accuracy: 400/411 (97%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.544622\n",
            "Validation set: Average loss: 0.523758, Accuracy: 401/411 (98%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.542554\n",
            "Validation set: Average loss: 0.522454, Accuracy: 404/411 (98%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.540814\n",
            "Validation set: Average loss: 0.521707, Accuracy: 404/411 (98%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.539469\n",
            "Validation set: Average loss: 0.519602, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.538033\n",
            "Validation set: Average loss: 0.516867, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.536373\n",
            "Validation set: Average loss: 0.515252, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.535080\n",
            "Validation set: Average loss: 0.514425, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.534016\n",
            "Validation set: Average loss: 0.512559, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.532671\n",
            "Validation set: Average loss: 0.510052, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.531516\n",
            "Validation set: Average loss: 0.510057, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.530662\n",
            "Validation set: Average loss: 0.509585, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.530020\n",
            "Validation set: Average loss: 0.507199, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.528842\n",
            "Validation set: Average loss: 0.505526, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.527701\n",
            "Validation set: Average loss: 0.504165, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.526750\n",
            "Validation set: Average loss: 0.503488, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.525828\n",
            "Validation set: Average loss: 0.501042, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.524773\n",
            "Validation set: Average loss: 0.500606, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.524019\n",
            "Validation set: Average loss: 0.498309, Accuracy: 405/411 (99%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.523246\n",
            "Validation set: Average loss: 0.497755, Accuracy: 405/411 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Review training and validation loss\n",
        "After training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n",
        "\n",
        "The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
        "The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
        "Let's plot the loss metrics and see:"
      ],
      "metadata": {
        "id": "cacw_AuqUEm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_IhSMIzHUHVt",
        "outputId": "ceff8ea6-e09b-4500-ad4e-41e2a3c1ae2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View the learned weights and biases\n",
        "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n",
        "\n",
        "Layer 1: There are four input values going to ten output nodes, so there should be 10 x 4 weights and 10 bias values.\n",
        "\n",
        "Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
        "\n",
        "Layer 3: There are ten input values going to three output nodes, so there should be 3 x 10 weights and 3 bias values."
      ],
      "metadata": {
        "id": "ZMyxKe3-UnaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\n\", model.state_dict()[param_tensor].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTq7DnEMUpqv",
        "outputId": "b91852c2-1617-4d3e-96f4-2471dbdfbd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight \n",
            " [[ 0.02229995 -0.35246706 -0.2752421  -0.29135275]\n",
            " [ 0.19775036 -0.6237761   0.02212173  0.08350384]\n",
            " [ 0.32231152 -0.37796003 -0.34325612 -0.29033077]\n",
            " [ 0.44929087 -0.5670486   0.33180645  0.17679961]\n",
            " [ 0.04045187  0.39468873 -0.03539526  0.0578948 ]\n",
            " [-0.11417234 -0.00351322  0.06379652 -0.39110255]\n",
            " [-0.2620657   0.40374637 -0.40577334 -0.0359031 ]\n",
            " [ 0.60263544  0.38030934 -0.06633069 -0.44905552]\n",
            " [ 0.24768895 -0.35614038 -0.14193213 -0.16775817]\n",
            " [-0.22024718  0.22054115  0.6350871   0.13495141]]\n",
            "fc1.bias \n",
            " [ 0.4478464   0.20768906 -0.31610698 -0.01876415 -0.1457353  -0.21191257\n",
            "  0.14706135  0.12003304  0.37511402  0.15581867]\n",
            "fc2.weight \n",
            " [[ 5.06236858e-04  3.49151284e-01 -3.05821389e-01  2.65271723e-01\n",
            "  -3.29438418e-01  4.35840944e-03 -5.37640229e-02 -4.09044147e-01\n",
            "   4.17961515e-02  4.08502996e-01]\n",
            " [-9.24395546e-02 -1.87742561e-01 -1.16953306e-01 -3.13428640e-01\n",
            "   1.42743304e-01 -1.51872724e-01 -2.11031526e-01 -1.82179257e-01\n",
            "   1.81817070e-01  1.67465895e-01]\n",
            " [ 2.42711723e-01  1.14703119e-01 -1.05607331e-01 -8.83692652e-02\n",
            "   9.34231505e-02  2.59950191e-01  8.59798566e-02 -1.49621695e-01\n",
            "  -1.48651525e-01 -2.98983544e-01]\n",
            " [ 6.83203787e-02  7.82676578e-01 -2.81941026e-01  4.05452281e-01\n",
            "  -2.90030599e-01 -3.59745584e-02  9.05972123e-02  1.08643979e-01\n",
            "  -2.12783888e-01 -5.75094819e-01]\n",
            " [ 2.52059579e-01  5.14941178e-02  2.62350321e-01 -1.06012389e-01\n",
            "   9.31466073e-02 -7.23137632e-02 -1.40630109e-02 -1.92596689e-01\n",
            "   1.06948525e-01  9.99804437e-02]\n",
            " [-6.52332697e-03 -1.03882514e-01 -1.94932222e-01  1.95710123e-01\n",
            "  -2.63199300e-01  1.29547596e-01 -1.06332697e-01 -1.34215578e-01\n",
            "   5.68087548e-02 -1.92444652e-01]\n",
            " [ 7.28604123e-02  2.31907461e-02 -2.34795779e-01  1.68439001e-02\n",
            "   9.17882249e-02  1.25172749e-01 -3.98063362e-02 -2.97866583e-01\n",
            "  -4.87477928e-02  7.09630921e-02]\n",
            " [-1.15384273e-01  1.20034084e-01  2.10595861e-01 -1.65118828e-01\n",
            "   3.11858347e-03  1.30759865e-01  2.47852504e-02  2.64149792e-02\n",
            "   3.94859090e-02 -2.48601735e-01]\n",
            " [ 2.48517860e-02  4.73931313e-01  2.84957200e-01  2.21352026e-01\n",
            "  -4.49468233e-02  1.47682860e-01 -1.53838366e-01 -5.10297179e-01\n",
            "  -2.71930933e-01  4.28619266e-01]\n",
            " [ 2.00738013e-01 -6.35745406e-01  1.23721778e-01  2.05027640e-01\n",
            "   4.77522194e-01  2.76507944e-01  2.44998664e-01  1.69770941e-01\n",
            "  -1.10977493e-01  2.99920470e-01]]\n",
            "fc2.bias \n",
            " [ 0.24353033 -0.19029923  0.28429422 -0.15264921  0.17238697 -0.21379894\n",
            "  0.05471132 -0.11085758  0.2803187   0.0493783 ]\n",
            "fc3.weight \n",
            " [[ 0.12311143  0.05616896  0.13454486 -0.10746291  0.1541836  -0.2208759\n",
            "   0.07142162 -0.21395713 -0.31197056 -0.25394854]\n",
            " [ 0.47787198  0.1710905   0.29668987  0.83462715 -0.28240576 -0.218082\n",
            "  -0.00452782 -0.20536852  0.44076523 -0.4065622 ]\n",
            " [-0.36670768 -0.30550492 -0.17953691  1.093686    0.25891465  0.1981934\n",
            "   0.21792449  0.28118545 -0.33549625  0.00431172]]\n",
            "fc3.bias \n",
            " [ 0.28173694 -0.05427741  0.07395431]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model performance\n",
        "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performance of a classification model is to create a confusion matrix that shows a crosstab of correct and incorrect predictions for each class."
      ],
      "metadata": {
        "id": "EfoTZsgWVciu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Set the model to evaluate mode\n",
        "model.eval()\n",
        "\n",
        "# Get predictions for the test data\n",
        "x = torch.Tensor(x_test).float()\n",
        "_, predicted = torch.max(model(x).data, 1)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted.numpy())\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(penguin_classes))\n",
        "plt.xticks(tick_marks, penguin_classes, rotation=45)\n",
        "plt.yticks(tick_marks, penguin_classes)\n",
        "plt.xlabel(\"Predicted Species\")\n",
        "plt.ylabel(\"Actual Species\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "5HVTnq5yVkVD",
        "outputId": "37480348-4526-4123-b5c4-44db568cda30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class."
      ],
      "metadata": {
        "id": "bihBYxN5WB5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the trained model\n",
        "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later"
      ],
      "metadata": {
        "id": "ZM0EyqZIWUMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "model_file = 'penguin_classifier.pt'\n",
        "torch.save(model.state_dict(), model_file)\n",
        "del model\n",
        "print('model saved as', model_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZHKBpsqWDAO",
        "outputId": "420a1040-95b6-44aa-e2db-a2230858f4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved as penguin_classifier.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the trained model\n",
        "When we have a new penguin observation, we can use the model to predict the species"
      ],
      "metadata": {
        "id": "DofWs4vHWw-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# New penguin features\n",
        "x_new = [[39.2,21.1,196.0,4150.0]]\n",
        "print ('New sample: {}'.format(x_new))\n",
        "\n",
        "# Create a new model class and load weights\n",
        "model = PenguinNet()\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Get a prediction for the new data sample\n",
        "x = torch.Tensor(x_new).float()\n",
        "_, predicted = torch.max(model(x).data, 1)\n",
        "\n",
        "print('Prediction:',penguin_classes[predicted.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys7c6M1_Wz-1",
        "outputId": "266b8e08-fe28-4ddb-df98-df64fef76551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New sample: [[39.2, 21.1, 196.0, 4150.0]]\n",
            "Prediction: Gentoo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning with TensorFlow"
      ],
      "metadata": {
        "id": "MqSic7vbaVLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icF_YoJbaau6",
        "outputId": "79e035ee-e67e-4209-9108-0ee58cde865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.21 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Set random seed for reproducability\n",
        "tensorflow.random.set_seed(0)\n",
        "\n",
        "print(\"Libraries imported.\")\n",
        "print('Keras version:',keras.__version__)\n",
        "print('TensorFlow version:',tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6RwRacTagnG",
        "outputId": "03df6c21-9c0d-4bd4-f4f1-8b44ec0472c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n",
            "Keras version: 2.11.0\n",
            "TensorFlow version: 2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for TensorFlow\n",
        "We've already loaded our data and split it into training and validation datasets. However, we need to do some further data preparation so that our data will work correctly with TensorFlow. Specifically, we need to set the data type of our features to 32-bit floating point numbers, and specify that the labels represent categorical classes rather than numeric values."
      ],
      "metadata": {
        "id": "nGoqmIUGanIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data types for float features\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Set data types for categorical labels\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "print('Ready...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAK2eELdaqFS",
        "outputId": "ddae39fa-b5e3-4023-f083-2832615e76f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a neural network\n",
        "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
        "\n",
        "An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a ReLU activation function.\n",
        "\n",
        "A hidden layer that receives ten inputs and applies a ReLU activation function.\n",
        "\n",
        "An output layer that uses a SoftMax activation function to generate an output for each penguin species (which represent the classification probabilities for each of the three possible penguin species). Softmax functions produce a vector with probability values that sum to 1."
      ],
      "metadata": {
        "id": "2jE4KuLJbLZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a classifier network\n",
        "hl = 10 # Number of hidden layer nodes\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(hl, input_dim=len(features), activation='relu'))\n",
        "model.add(Dense(hl, input_dim=hl, activation='relu'))\n",
        "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM_6xPIXbQSZ",
        "outputId": "b4974e55-772b-454f-8c2a-3b0b8e5d2f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                50        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 193\n",
            "Trainable params: 193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
        "\n",
        "To do this, we'll apply an Adam optimizer to a categorical cross-entropy loss function iteratively over 50 epochs."
      ],
      "metadata": {
        "id": "ZEo4DR-0eOc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper-parameters for optimizer\n",
        "learning_rate = 0.001\n",
        "opt = optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n",
        "num_epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMCb1A5VeSB8",
        "outputId": "751131dd-a454-4178-80d1-80a2dd371780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "96/96 [==============================] - 2s 9ms/step - loss: 4.7347 - accuracy: 0.3866 - val_loss: 1.0716 - val_accuracy: 0.3212\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 1.0029 - accuracy: 0.6520 - val_loss: 0.9010 - val_accuracy: 0.7421\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.8624 - accuracy: 0.5883 - val_loss: 0.8174 - val_accuracy: 0.8078\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.7971 - accuracy: 0.6917 - val_loss: 0.8030 - val_accuracy: 0.7105\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.8516 - val_loss: 0.7281 - val_accuracy: 0.8856\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.8485 - val_loss: 0.6736 - val_accuracy: 0.7372\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.8934 - val_loss: 0.6094 - val_accuracy: 0.9221\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.9039 - val_loss: 0.5625 - val_accuracy: 0.9294\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.9122 - val_loss: 0.5126 - val_accuracy: 0.9246\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.9279 - val_loss: 0.4682 - val_accuracy: 0.9270\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.9039 - val_loss: 0.4254 - val_accuracy: 0.9367\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.9363 - val_loss: 0.4044 - val_accuracy: 0.9221\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.9478 - val_loss: 0.3535 - val_accuracy: 0.9343\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.9415 - val_loss: 0.3203 - val_accuracy: 0.9684\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.9613 - val_loss: 0.3006 - val_accuracy: 0.9343\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.9551 - val_loss: 0.2520 - val_accuracy: 0.9513\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9655 - val_loss: 0.2262 - val_accuracy: 0.9732\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9603 - val_loss: 0.2217 - val_accuracy: 0.9611\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9634 - val_loss: 0.2003 - val_accuracy: 0.9708\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9718 - val_loss: 0.1971 - val_accuracy: 0.9538\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9697 - val_loss: 0.1587 - val_accuracy: 0.9757\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9687 - val_loss: 0.1750 - val_accuracy: 0.9513\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9760 - val_loss: 0.1551 - val_accuracy: 0.9611\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9781 - val_loss: 0.1219 - val_accuracy: 0.9805\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9801 - val_loss: 0.1138 - val_accuracy: 0.9781\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9791 - val_loss: 0.1054 - val_accuracy: 0.9805\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9812 - val_loss: 0.1013 - val_accuracy: 0.9805\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9812 - val_loss: 0.0985 - val_accuracy: 0.9854\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9801 - val_loss: 0.0949 - val_accuracy: 0.9781\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9812 - val_loss: 0.0886 - val_accuracy: 0.9781\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9801 - val_loss: 0.0787 - val_accuracy: 0.9805\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9791 - val_loss: 0.0748 - val_accuracy: 0.9781\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9770 - val_loss: 0.0717 - val_accuracy: 0.9927\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9854 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9843 - val_loss: 0.0633 - val_accuracy: 0.9903\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9843 - val_loss: 0.0609 - val_accuracy: 0.9878\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9875 - val_loss: 0.0646 - val_accuracy: 0.9781\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9927\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9885 - val_loss: 0.0573 - val_accuracy: 0.9805\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9770 - val_loss: 0.0514 - val_accuracy: 0.9927\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9875 - val_loss: 0.0495 - val_accuracy: 0.9927\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9801 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 0.0463 - val_accuracy: 0.9927\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.0552 - val_accuracy: 0.9781\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9896 - val_loss: 0.0471 - val_accuracy: 0.9854\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.0458 - val_accuracy: 0.9830\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.0527 - val_accuracy: 0.9854\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9906 - val_loss: 0.0617 - val_accuracy: 0.9708\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0447 - val_accuracy: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review training and validation loss\n",
        "After training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n",
        "\n",
        "The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
        "\n",
        "The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
        "\n",
        "Let's plot the loss metrics and see:"
      ],
      "metadata": {
        "id": "fEsm-C19ey-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "epoch_nums = range(1,num_epochs+1)\n",
        "training_loss = history.history[\"loss\"]\n",
        "validation_loss = history.history[\"val_loss\"]\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-XSAkTkoe37Y",
        "outputId": "33d04664-fcc5-4791-fe60-88457e57eed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## View the learned weights and biases\n",
        "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n",
        "\n",
        "Layer 1: There are four input values going to ten output nodes, so there should be 4 x 10 weights and 10 bias values.\n",
        "Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
        "Layer 3: There are ten input values going to three output nodes, so there should be 10 x 3 weights and 3 bias values."
      ],
      "metadata": {
        "id": "BrHoTSLIfNTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()[0]\n",
        "    biases = layer.get_weights()[1]\n",
        "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YITLEPdpfSsg",
        "outputId": "3c480095-665c-4030-9a38-b1f1e30276ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------\n",
            "Weights:\n",
            " [[ 0.34819221 -0.22542676  0.14334998 -0.20979366  0.22670588  0.44623157\n",
            "  -0.28841475  0.44679496 -0.36357725 -0.07718617]\n",
            " [-1.2847741   1.1874338  -0.13798    -0.4187045   0.15522899  0.90032756\n",
            "   0.01894599  0.2556485  -0.03043526  0.18137999]\n",
            " [ 0.47098175 -0.05068964 -0.33816677 -0.56706834 -0.3067076  -0.36346814\n",
            "  -0.60682994 -0.44267845 -0.3830216   0.36973584]\n",
            " [ 0.5962808   0.35482445  0.31327745 -0.32505646  0.3239517   0.10458663\n",
            "  -0.38811812 -0.29632512  0.4024192  -0.08509042]] \n",
            "Biases:\n",
            " [-0.4929077   0.5579143  -0.30228546  0.         -0.28083572  0.08357517\n",
            "  0.         -0.25139266  0.         -0.0186032 ]\n",
            "------------\n",
            "Weights:\n",
            " [[-0.086155   -0.11518669  0.5306053  -0.2404179  -0.33351478  0.44563007\n",
            "   0.30535477 -0.02052689 -0.00245721 -0.2632157 ]\n",
            " [ 0.44838813  0.17644018 -0.42204303  0.2937833  -0.23094887  0.36441952\n",
            "   0.22033644 -0.26164812 -0.06387301  0.39393783]\n",
            " [-0.08728151  0.21185625  0.39471284  0.24197084  0.09860706  0.2998498\n",
            "  -0.51714075  0.05043489  0.01288748 -0.4603289 ]\n",
            " [-0.10753495  0.07089049 -0.0168553  -0.253214    0.0878374   0.0520032\n",
            "   0.13625187  0.48196185  0.3628506  -0.20380086]\n",
            " [-0.14715551 -0.5451188   0.0563231  -0.47085947 -0.17422709 -0.05194688\n",
            "  -0.08488184 -0.44853517  0.31382582 -0.4502102 ]\n",
            " [ 0.5037798   0.09114951 -0.01113098 -0.11136988  0.34801954  0.2485394\n",
            "  -0.40999693 -0.44803554 -0.20198224  0.05411637]\n",
            " [-0.12889692  0.4546348  -0.32022262 -0.23856395 -0.07909331 -0.13806885\n",
            "   0.13738602  0.27708274 -0.38115126 -0.5039535 ]\n",
            " [ 1.6157691   0.2778433   0.7003813  -0.11305341  0.21909952 -0.47750175\n",
            "   0.17611998 -0.34003377 -0.3414004   0.23244792]\n",
            " [-0.3738313  -0.3017854  -0.37684447  0.0065645  -0.21724218  0.44818586\n",
            "  -0.27008158  0.1427393  -0.38239548 -0.29203093]\n",
            " [-0.13684946 -0.33437476 -0.38942555  0.01936126  0.3009117  -0.22297265\n",
            "   0.05543339  0.14306378  0.0798012  -0.28528285]] \n",
            "Biases:\n",
            " [-0.00435975  0.         -0.48814073  0.         -0.04890417  0.17854401\n",
            "  0.          0.         -0.07247062  0.        ]\n",
            "------------\n",
            "Weights:\n",
            " [[ 0.02910139 -0.5043763   0.3918371 ]\n",
            " [-0.5455884  -0.64140046  0.19192308]\n",
            " [-0.5786633   0.3501421   0.7957798 ]\n",
            " [ 0.5052029  -0.37494525 -0.3405466 ]\n",
            " [-0.41128942  0.33081144 -0.30114287]\n",
            " [ 0.14390118  0.32613188 -0.5657873 ]\n",
            " [-0.11124182 -0.21662226  0.23684222]\n",
            " [-0.26089305  0.5045738   0.6091012 ]\n",
            " [-0.3371984   0.03859415  0.3321735 ]\n",
            " [-0.39008573 -0.46101975  0.48723984]] \n",
            "Biases:\n",
            " [ 0.4381569  -0.24956733 -0.23874368]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model performance\n",
        "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performance of a classification model is to create a confusion matrix that shows a crosstab of correct and incorrect predictions for each class."
      ],
      "metadata": {
        "id": "aumCMeFTfaFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "class_probabilities = model.predict(x_test)\n",
        "predictions = np.argmax(class_probabilities, axis=1)\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(penguin_classes))\n",
        "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
        "plt.yticks(tick_marks, penguin_classes)\n",
        "plt.xlabel(\"Predicted Species\")\n",
        "plt.ylabel(\"Actual Species\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "0T7wP0uOfftP",
        "outputId": "bd7362c1-d6e7-4f4f-a787-3c10c15cfd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model\n",
        "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later."
      ],
      "metadata": {
        "id": "po90zVZIfloB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "modelFileName = 'models/penguin-classifier.h5'\n",
        "model.save(modelFileName)\n",
        "del model  # deletes the existing model variable\n",
        "print('model saved as', modelFileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r88eRgKfnrZ",
        "outputId": "22218092-5234-4618-fff7-b89c20137366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved as models/penguin-classifier.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the trained model\n",
        "When we have a new penguin observation, we can use the model to predict the species."
      ],
      "metadata": {
        "id": "i7rpsltOfqmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = models.load_model(modelFileName)\n",
        "\n",
        "# CReate a new array of features\n",
        "x_new = np.array([[50.4,15.3,20,50]])\n",
        "print ('New sample: {}'.format(x_new))\n",
        "\n",
        "# Use the model to predict the class\n",
        "class_probabilities = model.predict(x_new)\n",
        "predictions = np.argmax(class_probabilities, axis=1)\n",
        "\n",
        "print(penguin_classes[predictions[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucl4orAkftzS",
        "outputId": "f0950b8e-625a-4c73-8d1e-27d77e024098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New sample: [[50.4 15.3 20.  50. ]]\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "Gentoo\n"
          ]
        }
      ]
    }
  ]
}